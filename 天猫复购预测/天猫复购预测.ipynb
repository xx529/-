{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 天猫用户复购预测\n",
    "\n",
    "**天池比赛地址**\n",
    "\n",
    "https://tianchi.aliyun.com/competition/entrance/231576/introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集\n",
    "\n",
    "**user_id**: A unique id for the shopper.\n",
    "\n",
    "**merchant_id**: A unique id for the merchant.\n",
    "\n",
    "**label**: It is an enumerated type {0, 1}, \n",
    "* 1 : for repeat buyer\n",
    "* 0 : for non-repeat buyer\n",
    "* empty: for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  label\n",
       "0    34176         3906      0\n",
       "1    34176          121      0\n",
       "2    34176         4356      1\n",
       "3    34176         2217      0\n",
       "4   230784         4818      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.read_csv('./train_format1.csv')\n",
    "train_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260864 entries, 0 to 260863\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype\n",
      "---  ------       --------------   -----\n",
      " 0   user_id      260864 non-null  int64\n",
      " 1   merchant_id  260864 non-null  int64\n",
      " 2   label        260864 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 6.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    244912\n",
       "1     15952\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户信息表\n",
    "\n",
    "**user_id**：A unique id for the shopper.\n",
    "\n",
    "**age_range**\n",
    "* 1 for <18; \n",
    "* 2 for [18,24]; \n",
    "* 3 for [25,29]; \n",
    "* 4 for [30,34]; \n",
    "* 5 for [35,39]; \n",
    "* 6 for [40,49]; \n",
    "* 7 for >= 50 \n",
    "* 8 for >= 50 \n",
    "* NULL for unknown.\n",
    "* 0 for unknown\n",
    "\n",
    "**gender**\n",
    "* 0 for female\n",
    "* 1 for male\n",
    "* 2 and NULL for unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>376517</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>234512</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>344532</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186135</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30230</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age_range  gender\n",
       "0   376517        6.0     1.0\n",
       "1   234512        5.0     0.0\n",
       "2   344532        5.0     0.0\n",
       "3   186135        5.0     0.0\n",
       "4    30230        5.0     0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info_raw = pd.read_csv('./user_info_format1.csv')\n",
    "user_info_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424170 entries, 0 to 424169\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   user_id    424170 non-null  int64  \n",
      " 1   age_range  421953 non-null  float64\n",
      " 2   gender     417734 non-null  float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 9.7 MB\n"
     ]
    }
   ],
   "source": [
    "user_info_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "age_range    2217\n",
       "gender       6436\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户行为表\n",
    "\n",
    "**user_id**：A unique id for the shopper.\n",
    "\n",
    "**item_id**：A unique id for the item.\n",
    "\n",
    "**cat_id**：A unique id for the category that the item belongs to.\n",
    "\n",
    "**seller_id**：A unique id for the merchant.\n",
    "\n",
    "**brand_id**：A unique id for the brand of the item.\n",
    "\n",
    "**time_tamp**：Date the action took place (format: mmdd)\n",
    "\n",
    "**action_type**：It is an enumerated type {0, 1, 2, 3}\n",
    "* 0 is for click\n",
    "* 1 is for add-to-cart\n",
    "* 2 is for purchase \n",
    "* 3 is for add-to-favourite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>action_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328862</td>\n",
       "      <td>323294</td>\n",
       "      <td>833</td>\n",
       "      <td>2882</td>\n",
       "      <td>2661.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>328862</td>\n",
       "      <td>844400</td>\n",
       "      <td>1271</td>\n",
       "      <td>2882</td>\n",
       "      <td>2661.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328862</td>\n",
       "      <td>575153</td>\n",
       "      <td>1271</td>\n",
       "      <td>2882</td>\n",
       "      <td>2661.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>328862</td>\n",
       "      <td>996875</td>\n",
       "      <td>1271</td>\n",
       "      <td>2882</td>\n",
       "      <td>2661.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>328862</td>\n",
       "      <td>1086186</td>\n",
       "      <td>1271</td>\n",
       "      <td>1253</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  cat_id  merchant_id  brand_id  time_stamp  action_type\n",
       "0   328862   323294     833         2882    2661.0         829            0\n",
       "1   328862   844400    1271         2882    2661.0         829            0\n",
       "2   328862   575153    1271         2882    2661.0         829            0\n",
       "3   328862   996875    1271         2882    2661.0         829            0\n",
       "4   328862  1086186    1271         1253    1049.0         829            0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log_raw = pd.read_csv('./user_log_format1.csv')\n",
    "user_log_raw.rename(columns={'seller_id': 'merchant_id'}, inplace=True)\n",
    "user_log_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54925330 entries, 0 to 54925329\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   user_id      int64  \n",
      " 1   item_id      int64  \n",
      " 2   cat_id       int64  \n",
      " 3   merchant_id  int64  \n",
      " 4   brand_id     float64\n",
      " 5   time_stamp   int64  \n",
      " 6   action_type  int64  \n",
      "dtypes: float64(1), int64(6)\n",
      "memory usage: 2.9 GB\n"
     ]
    }
   ],
   "source": [
    "user_log_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id            0\n",
       "item_id            0\n",
       "cat_id             0\n",
       "merchant_id        0\n",
       "brand_id       91015\n",
       "time_stamp         0\n",
       "action_type        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上传数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163968</td>\n",
       "      <td>4605</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360576</td>\n",
       "      <td>1581</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98688</td>\n",
       "      <td>1964</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98688</td>\n",
       "      <td>3645</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295296</td>\n",
       "      <td>3361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  prob\n",
       "0   163968         4605   NaN\n",
       "1   360576         1581   NaN\n",
       "2    98688         1964   NaN\n",
       "3    98688         3645   NaN\n",
       "4   295296         3361   NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上传数据格式\n",
    "sub = pd.read_csv('./test_format1.csv')\n",
    "sub.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充缺失值\n",
    "user_info_raw.fillna(value={'age_range': 0, 'gender': 2}, inplace=True)\n",
    "user_log_raw.fillna(value={'brand_id': 0.0}, inplace=True)\n",
    "\n",
    "# 时间格式更改\n",
    "user_log_raw['time_stamp'] = pd.to_datetime(user_log_raw['time_stamp'], format='%m%d')\n",
    "\n",
    "# 测试集增加标记\n",
    "sub['label'] = 3\n",
    "sub_drop = sub.drop(labels='prob', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(train, test, user_info, activity_log):\n",
    "\n",
    "    # --- creat return set -----------------------------------------------\n",
    "    df = pd.concat([train, test], axis=0)\n",
    "    df.sort_values('user_id', inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # --- user featres ----------------------------------------------------\n",
    "    user_group =  activity_log.groupby('user_id')\n",
    "    \n",
    "    ## 年龄与性别 one-hot 编码\n",
    "    cols = ['age_range', 'gender']\n",
    "    df = pd.merge(df, user_info, how='left', on='user_id')\n",
    "    df = pd.get_dummies(df, columns=cols)\n",
    "    \n",
    "    ## 用户交互行为数量\n",
    "    df_temp = user_group.size().reset_index().rename(columns={0: 'user_log_count'})\n",
    "    df = pd.merge(df, df_temp, how='left', on='user_id')\n",
    "    \n",
    "    ## 分别对item_id, cat_id, merchant_id, brand_id, action_type 的唯一值个数\n",
    "    cols = ['item_id', 'cat_id', 'merchant_id', 'brand_id', 'action_type']\n",
    "    for col in cols:\n",
    "        df_temp = user_group.agg({col: 'nunique'})\n",
    "        df_temp.rename(columns={col: 'user_{}_nunique'.format(col)}, inplace=True)\n",
    "        df = pd.merge(df, df_temp, how='left', on='user_id')\n",
    "    \n",
    "    ## 分别对每种 action_type 的次数统计\n",
    "    df_temp = user_group['action_type'].value_counts().unstack().reset_index()\n",
    "    df_temp.rename(columns={x: 'user_action_type_{}'.format(x) for x in range(4)}, inplace=True)\n",
    "    df_temp.fillna(value=0, inplace=True)\n",
    "    df = pd.merge(df, df_temp, how='left', on='user_id')\n",
    "    \n",
    "    ## 行为最迟时间与最早时间的差值\n",
    "    df_max = user_group.agg({'time_stamp': 'max'})\n",
    "    df_min = user_group.agg({'time_stamp': 'min'})\n",
    "    df_temp = (df_max - df_min).reset_index()\n",
    "    df_temp['time_stamp'] = df_temp['time_stamp'].apply(lambda x: x.days)\n",
    "    df = pd.merge(df, df_temp, how='left', on='user_id')\n",
    "    \n",
    "    ## 用户购买点击比\n",
    "    df['user_buy_click_ratio'] = df['user_action_type_2'] / df['user_action_type_0']\n",
    "    df['user_buy_click_ratio'] = df['user_buy_click_ratio'].apply(lambda x: x if x != np.inf else 1)\n",
    "    \n",
    "    ## 用户活跃程度，行为次数/时间差\n",
    "    df['user_activity_ratio'] = df['user_log_count'] / df['time_stamp']\n",
    "    \n",
    "    ## 用户忠诚程度，包括item、cat、merchant、brand用户行为除以这些的唯一值，值越大越忠诚\n",
    "    cols = ['item_id', 'cat_id', 'merchant_id', 'brand_id']\n",
    "    for col in cols:\n",
    "        new_col = 'user_{}_activity_ratio'.format(col)\n",
    "        nunique_col = 'user_{}_nunique'.format(col)\n",
    "        df[new_col] = df['user_log_count'] / df[nunique_col]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # --- merchant features -------------------------------------------------\n",
    "    merchant_group = activity_log.groupby('merchant_id')\n",
    "    \n",
    "    ## 商家被交互行为数量\n",
    "    df_temp = merchant_group.size().reset_index().rename(columns={0: 'merchant_log_count'})\n",
    "    df = pd.merge(df, df_temp, how='left', on='merchant_id')\n",
    "    \n",
    "    ## 统计商家拥有的item_id, cat_id, user_id, brand_id, action_type的唯一值个数\n",
    "    cols = ['item_id', 'user_id', 'cat_id', 'brand_id', 'action_type']\n",
    "    for col in cols:\n",
    "        df_temp = merchant_group.agg({col: 'nunique'})\n",
    "        df_temp.rename(columns={col: 'merchant_{}_nunique'.format(col)}, inplace=True)\n",
    "        df = pd.merge(df, df_temp, how='left', on='merchant_id')\n",
    "    \n",
    "    ## 商家被交互的 action_typed 的唯一值分别次数\n",
    "    df_temp = merchant_group['action_type'].value_counts().unstack().reset_index()\n",
    "    df_temp.rename(columns={x: 'merchant_action_type_{}'.format(x) for x in range(4)}, inplace=True)\n",
    "    df_temp.fillna(value=0, inplace=True)\n",
    "    df = pd.merge(df, df_temp, how='left', on='merchant_id')\n",
    "    \n",
    "    ## 商家购买点击比\n",
    "    df['merchant_buy_click_ratio'] = df['merchant_action_type_2'] / df['merchant_action_type_0']\n",
    "    df['merchant_buy_click_ratio'] = df['merchant_buy_click_ratio'].apply(lambda x: x if x<=1 else 1)\n",
    "    \n",
    "    ## 商家的item_id, cat_id, user_id, brand_id的丰富程度，与整体最大值的比例\n",
    "    cols = ['item_id', 'cat_id', 'user_id', 'brand_id']\n",
    "    for col in cols:\n",
    "        new_col_name = 'merchant_{}_ratio'.format(col)\n",
    "        nunique_col_name = 'merchant_{}_nunique'.format(col)\n",
    "        df[new_col_name] = df[nunique_col_name] / df[nunique_col_name].max()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #--- user merchant activites ---------------------------------------------\n",
    "    user_merchant_group = activity_log.groupby(['user_id', 'merchant_id'])\n",
    "    \n",
    "    # user在当前的merchant的item_id, cat_id, brand_id, action_type的唯一值个数\n",
    "    cols = ['item_id', 'cat_id', 'brand_id', 'action_type']\n",
    "    for col in cols:\n",
    "        df_temp = user_merchant_group.agg({col: 'nunique'})\n",
    "        df_temp.rename(columns={col: 'user_merchant_{}_nunique'.format(col)}, inplace=True)\n",
    "        df = pd.merge(df, df_temp, how='left', on=['user_id', 'merchant_id'])\n",
    "    \n",
    "    # 统计user在当前的merchant交互次数\n",
    "    df_temp = user_merchant_group.size().reset_index().rename(columns={0: 'user_merchant_log_count'})\n",
    "    df = pd.merge(df, df_temp, how='left', on=['user_id', 'merchant_id'])\n",
    "    \n",
    "    # user在当前meichant交互的 action_typed 的唯一值分别次数\n",
    "    df_temp = user_merchant_group['action_type'].value_counts().unstack().reset_index()\n",
    "    df_temp.rename(columns={x: 'user_merchant_action_type_{}'.format(x) for x in range(4)}, inplace=True)\n",
    "    df_temp.fillna(value=0, inplace=True)\n",
    "    df = pd.merge(df, df_temp, how='left', on=['user_id', 'merchant_id'])\n",
    "    \n",
    "    ## user在当前merchant的购买点击比\n",
    "    df['user_merchant_buy_click_ratio'] = df['user_merchant_action_type_2'] / df['user_merchant_action_type_0']\n",
    "    df['user_merchant_buy_click_ratio'] = df['user_merchant_buy_click_ratio'].apply(lambda x: x if x<=1 else 1)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # --- merchant item activites ---------------------------------------------\n",
    "    \n",
    "    # --- split df ------------------------------------------------------------\n",
    "    train = df[(df['label']==1) | (df['label']==0)].drop('label', axis=1)\n",
    "    label = df[(df['label']==1) | (df['label']==0)]['label']\n",
    "    test = df.query('label == 3').drop('label', axis=1)\n",
    "    \n",
    "    return train, label, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape (260864, 56)\n",
      "label_set shape (260864,)\n",
      "test_set shape (261477, 56)\n"
     ]
    }
   ],
   "source": [
    "# 获取特征数据\n",
    "train_set, label_set, test_set = build_features(train_raw, sub_drop, user_info_raw, user_log_raw)\n",
    "print('train_set shape', train_set.shape)\n",
    "print('label_set shape', label_set.shape)\n",
    "print('test_set shape', test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据规范化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除 user_id 和 merchant_id\n",
    "features_col = [x for x in train_set.columns if x not in ['user_id', 'merchant_id']]\n",
    "x_train = train_set[features_col]\n",
    "x_test = test_set[features_col]\n",
    "y_train = label_set\n",
    "\n",
    "# 数据规范化\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=2000)\n",
    "lr.fit(x_train, y_train)\n",
    "predict_proba = lr.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set = test_set.copy()\n",
    "sub_set['prob'] = predict_proba[:,1]\n",
    "result = pd.merge(sub[['user_id', 'merchant_id']], sub_set[['user_id', 'merchant_id', 'prob']], how='left', on=['user_id', 'merchant_id'])\n",
    "result.to_csv('./lr_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score: 0.6326483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(n_estimators=300)\n",
    "lgb.fit(x_train, y_train)\n",
    "predict_proba = lgb.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set = test_set.copy()\n",
    "sub_set['prob'] = predict_proba[:,1]\n",
    "result = pd.merge(sub[['user_id', 'merchant_id']], sub_set[['user_id', 'merchant_id', 'prob']], how='left', on=['user_id', 'merchant_id'])\n",
    "result.to_csv('./lgb_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score: 0.6723456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train, y_train)\n",
    "predict_proba = xgb.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_set = test_set.copy()\n",
    "sub_set['prob'] = predict_proba[:,1]\n",
    "result = pd.merge(sub[['user_id', 'merchant_id']], sub_set[['user_id', 'merchant_id', 'prob']], how='left', on=['user_id', 'merchant_id'])\n",
    "result.to_csv('./xgb_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score: 0.6673236"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征构造\n",
    "在机器学习特征数据基础上，增加 merchant 和 action_type 的 sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_din_features(train_set, test_set, activity_log):\n",
    "    \n",
    "    # 对每个 user 生成 sequence 的 list\n",
    "    user_group = activity_log.groupby('user_id')\n",
    "    temp = user_group[['merchant_id','action_type']].agg(lambda x: list(x))\n",
    "    temp.columns = ['merchant_id_seq','action_type_seq']\n",
    "    \n",
    "    # action_type 映射（留出0作为补全长度用）\n",
    "    type_to_idx = {0:1, 1:2, 2:3, 3:4}\n",
    "    temp['action_type_seq'] = temp['action_type_seq'].apply(lambda x: [type_to_idx[y] for y in x])\n",
    "    \n",
    "    # 固定两个 sequence 长度为500，不足的在后面补0\n",
    "    length = 500\n",
    "    for col in temp.columns:\n",
    "        temp[col] = temp[col].apply(lambda x: (x + [0]*length)[:length])\n",
    "        \n",
    "    # 默认所有用户 action_type 为3\n",
    "    train_set['action_type'], test_set['action_type'] = 3, 3\n",
    "    \n",
    "    # 与原来数据合并\n",
    "    temp = temp.reset_index()    \n",
    "    train = pd.merge(train_set, temp, how='left', on='user_id')\n",
    "    test = pd.merge(test_set, temp, how='left', on='user_id')\n",
    "    \n",
    "    # train里有seq空白\n",
    "    train.dropna(axis=0, inplace=True)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "din_train_set shape (260864, 59)\n",
      "din_test_set shape (261477, 59)\n"
     ]
    }
   ],
   "source": [
    "# 获得新数据并查看维度\n",
    "din_train_set, din_test_set  = add_din_features(train_set, test_set, user_log_raw)\n",
    "\n",
    "print('din_train_set shape', din_train_set.shape)\n",
    "print('din_test_set shape', din_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIN 模型构建\n",
    "在这一步一直报错：model_din = DIN(features_col, sequence_features)  # 这一步一直处理不到的bug\n",
    "\n",
    "一直提醒‘tuple index out of range’，没有查出原因，故此部分没有完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deepctr.models import DIN\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat,get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522341, 59)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方便计算唯 vocabulary_size\n",
    "temp_set = din_train_set.append(din_test_set)\n",
    "temp_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b0390bb26c3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# 模型定义  feature_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mmodel_din\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDIN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;31m# model = DIN(feature_columns, behavior_feature_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# model.compile('adam', 'binary_crossentropy', metrics=['binary_crossentropy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/deepctr/models/din.py\u001b[0m in \u001b[0;36mDIN\u001b[0;34m(dnn_feature_columns, history_feature_list, dnn_use_bn, dnn_hidden_units, dnn_activation, att_hidden_size, att_activation, att_weight_normalization, l2_reg_dnn, l2_reg_embedding, dnn_dropout, seed, task)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mdnn_input_emb_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msequence_embed_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mkeys_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys_emb_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mdeep_input_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_input_emb_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mquery_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_emb_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/deepctr/layers/utils.py\u001b[0m in \u001b[0;36mconcat_func\u001b[0;34m(inputs, axis, mask)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    490\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;31m# Used purely for shape validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m       raise ValueError('A `Concatenate` layer should be called '\n\u001b[1;32m    494\u001b[0m                        'on a list of at least 2 inputs')\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# 离散特征列构造\n",
    "sparse_col =[\n",
    "    SparseFeat('user_id', 424170+1, embedding_dim=10),\n",
    "    SparseFeat('merchant_id', 49959+1, embedding_dim=10),\n",
    "    SparseFeat('action_type', 4+1, embedding_dim=4),\n",
    "]\n",
    "\n",
    "# 连续特征列构造\n",
    "dense_col = [DenseFeat(x, 1) for x in din_train_set.columns if x not in ['user_id', 'merchant_id', 'merchant_id_seq', 'action_type_seq', 'action_type']]\n",
    "\n",
    "# 时序特征列构造\n",
    "varlen_col = [VarLenSparseFeat(\n",
    "    SparseFeat('merchant_id_seq', vocabulary_size=49959+1, embedding_dim=8, embedding_name='merchant_id'), maxlen=500),\n",
    "              VarLenSparseFeat(\n",
    "    SparseFeat('action_type_seq', vocabulary_size=4+1, embedding_dim=8, embedding_name='action_type'), maxlen=500)\n",
    "]\n",
    "\n",
    "# 整合以上特征列\n",
    "features_col = sparse_col + dense_col + varlen_col\n",
    "\n",
    "# 时序的列名\n",
    "sequence_features = ['action_type', 'merchant_id']\n",
    "\n",
    "# 模型定义  feature_columns\n",
    "model_din = DIN(features_col, sequence_features)  # 这一步一直处理不到的bug\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIN 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入格式为字典形式\n",
    "train_input = {x: train_set[x].values for x in train_set.columns}\n",
    "test_input = {x: test_set[x].values for x in test_set.columns}\n",
    "label_input = label_set.values\n",
    "\n",
    "# 模型训练\n",
    "history = model_din.fit(train_input, label_input)\n",
    "\n",
    "# 模型预测\n",
    "proba = model.predict(test_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
